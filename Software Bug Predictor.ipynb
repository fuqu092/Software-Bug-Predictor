{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10324932,"sourceType":"datasetVersion","datasetId":6392751}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<font size=\"6\">Imports</font>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport math\nimport torch.nn as nn\nimport sklearn\nimport transformers\nimport warnings\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:02:33.659550Z","iopub.execute_input":"2024-12-29T17:02:33.659887Z","iopub.status.idle":"2024-12-29T17:02:33.664174Z","shell.execute_reply.started":"2024-12-29T17:02:33.659857Z","shell.execute_reply":"2024-12-29T17:02:33.663374Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"<font size=\"6\">Parameters</font>","metadata":{}},{"cell_type":"code","source":"model_name = 'distilbert-base-uncased'\nbatch_size = 40\ncvae_epochs = 200\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlr = 0.005\ninput_dim = 768\nhidden_dim = math.floor(math.sqrt(input_dim))\nlatent_dim = 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:54:58.995654Z","iopub.execute_input":"2024-12-29T16:54:58.995936Z","iopub.status.idle":"2024-12-29T16:54:59.000368Z","shell.execute_reply.started":"2024-12-29T16:54:58.995913Z","shell.execute_reply":"2024-12-29T16:54:58.999469Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:55:13.295383Z","iopub.execute_input":"2024-12-29T16:55:13.295905Z","iopub.status.idle":"2024-12-29T16:55:13.668613Z","shell.execute_reply.started":"2024-12-29T16:55:13.295872Z","shell.execute_reply":"2024-12-29T16:55:13.667864Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DistilBertModel(\n  (embeddings): Embeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (layer): ModuleList(\n      (0-5): 6 x TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (ffn): FFN(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          (activation): GELUActivation()\n        )\n        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"<font size=\"6\">Stage-1: Text Representation</font>","metadata":{}},{"cell_type":"code","source":"def get_dataset(dataset, tokenizer, model):\n    data = pd.read_csv(f'/kaggle/input/data-sbrp/{dataset}.csv')\n    text = data[\"sentences\"]\n    labels = data[\"Security\"]\n\n    sentence_embeddings = []\n\n    for sentence in text:\n        input = tokenizer(sentence, return_tensors='pt', add_special_tokens=True, \n                          truncation=True, padding=True)\n        input = {k: v.to(device) for k, v in input.items()}\n    \n        with torch.no_grad():\n            output = model(**input)\n    \n        embeddings = output[0]\n        embeddings = torch.mean(embeddings, dim=1)\n        sentence_embeddings.append(embeddings)\n\n    sentence_embeddings_tensor = torch.stack(sentence_embeddings).squeeze(1).to(device)\n    labels_tensor = torch.tensor(labels.values, dtype=torch.int64, device=device)\n\n    return sentence_embeddings_tensor, labels_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:58:19.897397Z","iopub.execute_input":"2024-12-29T16:58:19.897800Z","iopub.status.idle":"2024-12-29T16:58:19.903480Z","shell.execute_reply.started":"2024-12-29T16:58:19.897768Z","shell.execute_reply":"2024-12-29T16:58:19.902591Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"<font size=\"6\">Stage-2: CVAE Training</font>","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n  def __init__(self, layer_dims, latent_dim):\n    super(Encoder, self).__init__()\n\n    self.encoder = nn.Sequential()\n    for i in range(len(layer_dims)-1):\n      self.encoder.add_module(name = f'linear_{i}', module = nn.Linear(layer_dims[i], layer_dims[i+1]))  \n      self.encoder.add_module(name = f'relu_{i}', module = nn.ReLU())\n    \n    self.mean = nn.Linear(layer_dims[-1], latent_dim)\n    self.log_var = nn.Linear(layer_dims[-1], latent_dim)\n\n  def forward(self, x, labels):\n    labels = nn.functional.one_hot(labels, num_classes=2)\n    x = torch.cat((x, labels), dim=1)\n\n    x = self.encoder(x)\n    mean = self.mean(x)\n    log_var = self.log_var(x)\n\n    return mean, log_var","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:55:23.506099Z","iopub.execute_input":"2024-12-29T16:55:23.506397Z","iopub.status.idle":"2024-12-29T16:55:23.512207Z","shell.execute_reply.started":"2024-12-29T16:55:23.506374Z","shell.execute_reply":"2024-12-29T16:55:23.511347Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Decoder(nn.Module):\n  def __init__(self, layer_dims, input_dim):\n    super(Decoder, self).__init__()\n\n    self.decoder = nn.Sequential()\n    self.decoder.add_module(name = f'linear_{0}', module = nn.Linear(input_dim, layer_dims[0]))\n    self.decoder.add_module(name = f'relu_{0}', module = nn.ReLU())\n    for i in range(len(layer_dims)-2):\n      self.decoder.add_module(name = f'linear_{i+1}', module = nn.Linear(layer_dims[i], layer_dims[i+1]))\n      self.decoder.add_module(name = f'relu_{i+1}', module = nn.ReLU())\n    self.decoder.add_module(name = 'final', module=nn.Linear(layer_dims[-2], layer_dims[-1]))\n    self.decoder.add_module(name = 'sigmoid', module=nn.Sigmoid())\n  \n  def forward(self, x, labels):\n    labels = nn.functional.one_hot(labels, num_classes=2)\n    x = torch.cat((x, labels), dim=1)\n\n    x = self.decoder(x)\n\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:55:25.955944Z","iopub.execute_input":"2024-12-29T16:55:25.956369Z","iopub.status.idle":"2024-12-29T16:55:25.965278Z","shell.execute_reply.started":"2024-12-29T16:55:25.956333Z","shell.execute_reply":"2024-12-29T16:55:25.964206Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class CVAE(nn.Module):\n  def __init__(self, encoder_layer_dims, decoder_layer_dims, latent_dim, num_labels):\n    super(CVAE, self).__init__()\n    encoder_layer_dims[0] += num_labels\n    decoder_input_dim = latent_dim + num_labels\n\n    self.encoder = Encoder(encoder_layer_dims, latent_dim)\n    self.decoder = Decoder(decoder_layer_dims, decoder_input_dim)\n\n  def forward(self, x, labels):\n    mean, log_var = self.encoder(x, labels)\n    z = self.sampling(mean, log_var)\n    output = self.decoder(z, labels)\n\n    return mean, log_var, output\n\n  def sampling(self, mean, log_var):\n    batch_size, dim = mean.shape\n    epsilon = torch.randn(batch_size, dim, device=mean.device)\n    \n    return mean + torch.exp(log_var/2) * epsilon\n\n  def generate(self, z, labels):\n    return self.decoder(z, labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:55:28.171958Z","iopub.execute_input":"2024-12-29T16:55:28.172257Z","iopub.status.idle":"2024-12-29T16:55:28.178032Z","shell.execute_reply.started":"2024-12-29T16:55:28.172233Z","shell.execute_reply":"2024-12-29T16:55:28.177117Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def calc_loss(output, x, mean, log_var):\n    reconstruction_loss = nn.functional.mse_loss(output, x, reduction='sum')\n    kl_divergence_loss = -0.5 * torch.sum(1 + log_var - mean.pow(2) - torch.exp(log_var))\n    loss = reconstruction_loss + kl_divergence_loss\n\n    return (loss/x.size(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:55:30.735430Z","iopub.execute_input":"2024-12-29T16:55:30.735786Z","iopub.status.idle":"2024-12-29T16:55:30.740038Z","shell.execute_reply.started":"2024-12-29T16:55:30.735755Z","shell.execute_reply":"2024-12-29T16:55:30.739265Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_cvae(cvae_model, cvae_optim, cvae_dataloader):\n    print(\"Started training CVAE\")\n    \n    for epoch in range(cvae_epochs):\n      cvae_model.train()\n      running_loss = 0.0\n      count = 0\n      for input, label in cvae_dataloader:\n        input = input.to(device)\n        label = label.to(device)\n    \n        mean, log_var, output = cvae_model(input, label)\n    \n        loss = calc_loss(output, input, mean, log_var)\n        cvae_optim.zero_grad()\n        loss.backward()\n        cvae_optim.step()\n    \n        running_loss += loss.item()\n        count += 1\n    \n      if epoch % 100 == 0 or epoch == cvae_epochs-1:\n        print(f'Epoch: {epoch + 1}/{cvae_epochs}, Training Loss: {running_loss/count:.4f}')\n\n    print(\"Completed Training CVAE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T16:59:52.644882Z","iopub.execute_input":"2024-12-29T16:59:52.645170Z","iopub.status.idle":"2024-12-29T16:59:52.651271Z","shell.execute_reply.started":"2024-12-29T16:59:52.645149Z","shell.execute_reply":"2024-12-29T16:59:52.650270Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"<font size=\"6\">Stage-3: Synthesis</font>","metadata":{}},{"cell_type":"code","source":"def generate_data(cvae_model, diff_num, text_tensor, labels_tensor):\n    with torch.no_grad():\n      label_1 = torch.ones(diff_num).long().to(device)\n      z = torch.randn([diff_num, latent_dim]).to(device)\n      generated = cvae_model.generate(z, label_1)\n    \n    final_text = np.array(torch.cat((text_tensor, generated), dim=0).to('cpu'))\n    final_labels = np.array(torch.cat((labels_tensor, label_1), dim=0).to('cpu'))\n    \n    return final_text, final_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:01:36.063203Z","iopub.execute_input":"2024-12-29T17:01:36.063508Z","iopub.status.idle":"2024-12-29T17:01:36.068414Z","shell.execute_reply.started":"2024-12-29T17:01:36.063484Z","shell.execute_reply":"2024-12-29T17:01:36.067673Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"<font size=\"6\">Stage-4: Prediction</font>","metadata":{}},{"cell_type":"code","source":"def predict(final_text, final_labels):\n    warnings.filterwarnings(\"ignore\")\n    classifier = LogisticRegression()\n    \n    skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n    pd_list, pf_list, g_measure_list = [], [], []\n    \n    for train_index,test_index in skfold.split(final_text, final_labels):\n        x_train_fold = final_text[train_index]\n        y_train_fold = final_labels[train_index]\n        x_test_fold = final_text[test_index]\n        y_test_fold = final_labels[test_index]\n    \n        classifier.fit(x_train_fold, y_train_fold)\n        y_pred_lr = classifier.predict(x_test_fold)\n    \n        cm_lr = confusion_matrix(y_test_fold, y_pred_lr).ravel()\n        pd_lr = cm_lr[3]/(cm_lr[3]+cm_lr[2])\n        pf_lr = cm_lr[1]/(cm_lr[1]+cm_lr[0])\n        g_measure_lr = (2*pd_lr*(1-pf_lr))/(pd_lr+(1-pf_lr))\n        pd_list.append(pd_lr)\n        pf_list.append(pf_lr)\n        g_measure_list.append(g_measure_lr)\n    \n    print(f'g-measure: {round(np.average(g_measure_list),4)*100}')\n    print(f'pd: {round(np.average(pd_list),4)*100}')\n    print(f'pf: {round(np.average(pf_list),4)*100}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:02:50.611337Z","iopub.execute_input":"2024-12-29T17:02:50.611659Z","iopub.status.idle":"2024-12-29T17:02:50.617684Z","shell.execute_reply.started":"2024-12-29T17:02:50.611634Z","shell.execute_reply":"2024-12-29T17:02:50.616812Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"<font size=\"6\">Results</font>","metadata":{}},{"cell_type":"code","source":"def get_result(dataset):\n    print(f'For {dataset} dataset:')\n    \n    #Stage-1: Text Representation\n    text_tensor, labels_tensor = get_dataset(dataset, tokenizer, model)\n    diff_num = int(torch.sum(labels_tensor == 0) - torch.sum(labels_tensor == 1))\n    cvae_dataset = torch.utils.data.TensorDataset(text_tensor, labels_tensor)\n    cvae_dataloader = torch.utils.data.DataLoader(cvae_dataset, batch_size=batch_size, shuffle=True)\n    \n    #Stage-2: CVAE Training\n    cvae = CVAE(encoder_layer_dims = [input_dim, hidden_dim], \n                decoder_layer_dims = [hidden_dim, input_dim], \n                latent_dim=latent_dim, num_labels = 2)\n    cvae.to(device)\n    cvae_optim = torch.optim.Adam(cvae.parameters(), lr=lr)\n    train_cvae(cvae, cvae_optim, cvae_dataloader)\n\n    #Stage-3: Syntesize\n    final_text, final_labels = generate_data(cvae, diff_num, text_tensor, labels_tensor)\n\n    #Stage-4: Prediction\n    predict(final_text, final_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:02:55.328831Z","iopub.execute_input":"2024-12-29T17:02:55.329113Z","iopub.status.idle":"2024-12-29T17:02:55.334363Z","shell.execute_reply.started":"2024-12-29T17:02:55.329091Z","shell.execute_reply":"2024-12-29T17:02:55.333586Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"get_result(dataset=\"Ambari\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:02:57.380293Z","iopub.execute_input":"2024-12-29T17:02:57.380643Z","iopub.status.idle":"2024-12-29T17:03:17.433593Z","shell.execute_reply.started":"2024-12-29T17:02:57.380614Z","shell.execute_reply":"2024-12-29T17:03:17.431581Z"}},"outputs":[{"name":"stdout","text":"For Ambari dataset:\nStarted training CVAE\nEpoch: 1/200, Training Loss: 143.0759\nEpoch: 101/200, Training Loss: 46.9731\nEpoch: 200/200, Training Loss: 46.9481\nCompleted Training CVAE\ng-measure: 98.42999999999999\npd: 97.11999999999999\npf: 0.21\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"get_result(dataset=\"Camel\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:03:17.435545Z","iopub.execute_input":"2024-12-29T17:03:17.435994Z","iopub.status.idle":"2024-12-29T17:03:38.367114Z","shell.execute_reply.started":"2024-12-29T17:03:17.435951Z","shell.execute_reply":"2024-12-29T17:03:38.366116Z"}},"outputs":[{"name":"stdout","text":"For Camel dataset:\nStarted training CVAE\nEpoch: 1/200, Training Loss: 139.6729\nEpoch: 101/200, Training Loss: 43.7113\nEpoch: 200/200, Training Loss: 43.6520\nCompleted Training CVAE\ng-measure: 98.27\npd: 96.7\npf: 0.1\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"get_result(dataset=\"Chromium\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:04:30.629042Z","iopub.execute_input":"2024-12-29T17:04:30.629352Z","iopub.status.idle":"2024-12-29T17:19:00.388965Z","shell.execute_reply.started":"2024-12-29T17:04:30.629330Z","shell.execute_reply":"2024-12-29T17:19:00.387674Z"}},"outputs":[{"name":"stdout","text":"For Chromium dataset:\nStarted training CVAE\nEpoch: 1/200, Training Loss: 43.2202\nEpoch: 101/200, Training Loss: 40.1016\nEpoch: 200/200, Training Loss: 40.1011\nCompleted Training CVAE\ng-measure: 99.77000000000001\npd: 99.53999999999999\npf: 0.0\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"get_result(dataset=\"Derby\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:03:38.368719Z","iopub.execute_input":"2024-12-29T17:03:38.369118Z","iopub.status.idle":"2024-12-29T17:04:00.552846Z","shell.execute_reply.started":"2024-12-29T17:03:38.369066Z","shell.execute_reply":"2024-12-29T17:04:00.550335Z"}},"outputs":[{"name":"stdout","text":"For Derby dataset:\nStarted training CVAE\nEpoch: 1/200, Training Loss: 139.1097\nEpoch: 101/200, Training Loss: 43.6019\nEpoch: 200/200, Training Loss: 43.5409\nCompleted Training CVAE\ng-measure: 95.74000000000001\npd: 92.54\npf: 0.77\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"get_result(dataset=\"Wicket\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T17:04:00.554502Z","iopub.execute_input":"2024-12-29T17:04:00.554941Z","iopub.status.idle":"2024-12-29T17:04:21.198313Z","shell.execute_reply.started":"2024-12-29T17:04:00.554899Z","shell.execute_reply":"2024-12-29T17:04:21.197028Z"}},"outputs":[{"name":"stdout","text":"For Wicket dataset:\nStarted training CVAE\nEpoch: 1/200, Training Loss: 156.0859\nEpoch: 101/200, Training Loss: 43.6146\nEpoch: 200/200, Training Loss: 43.5827\nCompleted Training CVAE\ng-measure: 99.49\npd: 98.99\npf: 0.0\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}